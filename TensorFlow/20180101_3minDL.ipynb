{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3분 딥러닝 3장 실습\n",
    "\n",
    "# 20171130 목\n",
    "p.35~38\n",
    "\n",
    "작성된 소스 코드의 출처 : https://github.com/golbin/TensorFlow-Tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "print(hello)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.constant의 반환값은 Tensor()라고 해서 자료형과 속성에 대해 설명한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1., 2., 3.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[1., 2., 3.], [4., 5., 6.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서는 텐서플로에서 수학식 계산을 위한 가장 기본적인 자료형.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랭크 = '\\['의 갯수, 즉 차원 수. \n",
    "(예) 3 : 랭크 0, [3]: 랭크 1, [[3]]: 랭크 2, [[[3]]]: 랭크 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랭크 0부터 순서대로, 스칼라, 벡터, 행렬, ... n차원 텐서라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "셰이프는 랭크 별 원소 개수.\n",
    "(예) 3 : 랭크 0 셰이프 \\[\\], \\[3\\] : 랭크 1 셰이프 \\[1\\], [[[1., 2., 3.]],[[1., 2., 3.]]] : 랭크 3 셰이프 [2, 1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "c = tf.add(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로우 프로그램 구조 : 1. 그래프 생성(동그라미, tf.constant, tf.add, ...) 2. 그래프 실행(Session run). 이런 실행 방식을 '지연 실행' 또는 'Lazy Evaluation'이라고 부른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "print(sess.run(hello))\n",
    "print(sess.run([a, b, c]))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프의 실행은 세션 안에서 이루어져야 한다. 아래는 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "print(hello)\n",
    "\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "c = tf.add(a,b)\n",
    "print(c)\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))\n",
    "print(sess.run([a, b, c]))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정리 : 텐서플로우는 그래프 기반 머신러닝 라이브러리이다. 프로그램 실행은 그래프 생성, 그래프 실행 순으로 진행된다. 랭크는 \\[의 개수이며 차원 수를 의미한다. 랭크 0부터 스칼라, 벡터, 행렬, ... n차원 텐서라고 부른다. 셰이프는 각 랭크 별 원소 수를 뜻한다. [제일 큰 랭크의 원소수, 그 다음 랭크의 원소 수, ... ]로 적힌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20171206 수\n",
    "<br>\n",
    "p.38~43\n",
    "<br>\n",
    "플레이스홀더와 변수\n",
    "플레이스홀더 : 그래프에 입력 값을 담을 그릇(parameter)을 담당.\n",
    "변수(variable) : 학습 함수들이 학습 결과를 갱신하기 위해 사용하는 변수(가중치)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None : 크기가 정해져 있지 않다.\n",
    "X = tf.placeholder(tf.float32, [None, 3])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2,3],[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([2, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.random_normal은 정규 분포를 따르는 무작위 값으로 초기화한다는 뜻."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2,3]행렬 = 행이 2, 열이 3\n",
    "<br>\n",
    "(예) [[1,2,3],[1,2,3]] : [2, 3] 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(\"=== x_data ===\")\n",
    "print(x_data)\n",
    "print(\"=== W ===\")\n",
    "print(sess.run(W))\n",
    "print(\"=== b ===\")\n",
    "print(sess.run(b))\n",
    "print(\"=== expr ===\")\n",
    "print(sess.run(expr, feed_dict={X: x_data}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "placeholder가 session에서 돌아가려면 feed_dict를 통해 입력 데이터를 별도로 넣어야 에러가 나지 않는다.\n",
    "<br>\n",
    "애초에 placeholder는 그릇이니까 내용물을 feed_dict로 담는 건 자연스러운 일이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20171207 목\n",
    "\n",
    "p. 44~\n",
    "<br>\n",
    "선형 회귀 모델 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X,Y -> 관계(직선 또는 곡선)\n",
    "<br>\n",
    "X -관계(직선 또는 곡선)-> Y\n",
    "<br>\n",
    "머신러닝은 이렇게 X, Y의 관계를 찾아내서\n",
    "<br>\n",
    "새로운 X를 넣었을 때 Y를 예측하는 것을 기본으로 한다.\n",
    "<br>\n",
    "<br>\n",
    "균등 분포란 주사위를 던지는 확률이 모두 1/6이듯이 사건이 일어날 확률이 모두 동일한 확률 분포를 뜻한다.\n",
    "<br>\n",
    "손실 함수, loss function은 한 쌍의 데이터(x,y)에 대한 손실값을 계산하는 함수이다.\n",
    "<br>\n",
    "손실값이란 예측 값과 실제 값 사이의 차이를 뜻한다. 이 차이를 최소화할 수 있다면 예측도는 최대가 될 것이다.\n",
    "<br>\n",
    "손실값은 각 데이터에 대한 오차를 뜻하고, 비용(Cost)는 전체 데이터에 대한 손실을 뜻한다. 즉 각 손실값 등을 평균하는 것 등으로 구할 수 있다.\n",
    "<br>\n",
    "학습이란 W, b와 같은 변수에 다양한 값을 넣고 계산해서 손실값을 계산하고, 이 손실을 최소화하는 W, b를 구하는 과정이다.\n",
    "<br>\n",
    "손실 함수 중 대표적인 것이 예측 값 - 실제 값이다. 즉 차이, 거리를 뜻한다.\n",
    "<br>\n",
    "최소제곱 함수라고 하여서 이 차이에다가 제곱을 씌운 손실 함수를 아래 코드에 사용했다.\n",
    "<br>\n",
    "그리고 비용을 계산하기 위해 각 손실값들을 모두 더한 후 평균을 내는 reduce_mean을 사용했다. 여기서 reduce란 여러 개를 더해서 한 개의 숫자로 결과가 나오기 때문에 붙인 말로 보인다.\n",
    "<br>\n",
    "그렇다면 어떻게 비용을 최소화해야할까? 최적화 함수란 걸 쓰면 된다. 가장 유명한 게 경사하강법, Gradient Descent이다. 이는 손실함수의 미분값(변화량)을 변수에 반영(학습률을 곱해서 통제) 반영해서 손실값을 줄이는 새로운 변수를 갱신하는 방식을 택한다. 따라서 최적화함수를 많이 작동시키면 그 만큼 변수가 갱신될 것이고, 손실값도 점점 줄어들 것이다. (오버피팅은 일단 논외로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "\n",
    "X = tf.placeholder(tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
    "\n",
    "hypothesis = W * X + b # W와 X까 헁렬이 아니므로 matmul을 사용하지 않음.\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100):\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data,\n",
    "                                                           Y: y_data})\n",
    "        print(step, cost_val, sess.run(W), sess.run(b))\n",
    "    \n",
    "    print(\"\\n=== Test ===\")\n",
    "    print(\"X: 5, Y:\",sess.run(hypothesis, feed_dict={X: 5}))\n",
    "    print(\"X: 2.5 Y:\",sess.run(hypothesis, feed_dict={X: 2.5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20171208금\n",
    "p.52~<br>\n",
    "# Ch.4 기본 신경망 구현\n",
    "(이어서 해야 함)\n",
    "# 20171210 일\n",
    "(이어서 계속)\n",
    "p.62 ~<br>\n",
    "인공 신경망은 뉴런의 구조에서 영감을 받은 구조로 가중치+활성화 함수의 연결로 구성되어 있다.<br>\n",
    "가장 좋은 결과를 내기 위해 가중치를 일일이 찾을 수고를 제한된 볼츠만, 각종 활성화 함수, 역전파를 통해 찾을 수 있게 되었고, <br>\n",
    "데이터 수의 기하급수 증가, GPU에 의한 컴퓨팅 파워 증가로 인해 신경망 학습은 딥러닝이라는 이름 아래 최고의 호황을 누리고 있다. <br>\n",
    "역전파는 결과값과 실제값의 오차를 각 신경망에 역으로 넣어 계산해서 최종적으로 입력층까지 계산하는 방법이다. 이를 통해서 가중치를 수작업으로 한땀한땀 아닌 하나의 알고리즘으로써 유의미한 값을 갱신할 수 있게 해주었다. <br>\n",
    "<br>\n",
    "아래는 포유류와 조류를 구분하는 분류기 코드이다. <br>\n",
    "심층 신경망은 다음 시간에 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [털, 날개]\n",
    "x_data = np.array(\n",
    "[[0, 0],[1, 0],[1, 1],[0, 0],[0, 0],[0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [1, 0, 0],\n",
    "    [1, 0, 0],\n",
    "    [0, 0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([2, 3], -1., 1.))\n",
    "b = tf.Variable(tf.zeros([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = tf.add(tf.matmul(X, W),b)\n",
    "L = tf.nn.relu(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.nn.softmax(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(model), axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "axis = 1은 행 별로 더 하라는 뜻이다.<br>\n",
    "더한다는 것은 차원을 축소한다는 것과 동일하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본적인 경사하강법으로 최적화합니다.\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "# 텐서플로의 세션을 초기화합니다.\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 앞서 구성한 특징과 레이블 데이터를 이용해 학습을 100번 진행합니다.\n",
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y:y_data})\n",
    "    \n",
    "    # 학습 도중 10번에 한 번씩 손실값을 출력해봅니다.\n",
    "    if (step + 1) % 10 == 0:\n",
    "        print(step+1, sess.run(cost, feed_dict = {X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.argmax(model, axis = 1)\n",
    "target = tf.argmax(Y, axis = 1)\n",
    "print(\"예측값:\", sess.run(prediction, feed_dict={X:x_data}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict = {X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20171211 월\n",
    "p.68~<br>\n",
    "심층 신경망 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# [털, 날개]\n",
    "x_data = np.array(\n",
    "[[0, 0],[1, 0],[1, 1],[0, 0],[0, 0],[0, 1]])\n",
    "\n",
    "y_data = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [1, 0, 0],\n",
    "    [1, 0, 0],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([2, 10],-1.,1.))\n",
    "W2 = tf.Variable(tf.random_uniform([10, 3], -1., 1.))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([10]))\n",
    "b2 = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "L1 = tf.add(tf.matmul(X, W1),b1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "model = tf.add(tf.matmul(L1, W2),b2)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=model))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 앞서 구성한 특징과 레이블 데이터를 이용해 학습을 100번 진행합니다.\n",
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y:y_data})\n",
    "    \n",
    "    # 학습 도중 10번에 한 번씩 손실값을 출력해봅니다.\n",
    "    if (step + 1) % 10 == 0:\n",
    "        print(step+1, sess.run(cost, feed_dict = {X:x_data, Y:y_data}))\n",
    "\n",
    "prediction = tf.argmax(model, axis = 1)\n",
    "target = tf.argmax(Y, axis = 1)\n",
    "print(\"예측값:\", sess.run(prediction, feed_dict={X:x_data}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict = {X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20171212 화\n",
    "\n",
    "# Ch 5. 텐서보드와 모델 재사용\n",
    "\n",
    "(내일 예정)\n",
    "# 20171213 수\n",
    "(이어서 계속)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "data = np.loadtxt('./data.csv',delimiter=',',\n",
    "                 unpack=True, dtype='float32')\n",
    "\n",
    "x_data = np.transpose(data[0:2])\n",
    "y_data = np.transpose(data[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used to train, but to count train steps.\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.))\n",
    "L1 = tf.nn.relu(tf.matmul(X,W1))\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([10, 20], -1., 1.))\n",
    "L2 = tf.nn.relu(tf.matmul(L1,W2))\n",
    "\n",
    "W3 = tf.Variable(tf.random_uniform([20, 3], -1., 1.))\n",
    "model = tf.matmul(L2,W3)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=model))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망의 층 수와 은닉층의 뉴런 수를 늘리면 좀더 복잡한 문제를 푸는데 좋은 성능을 거둘 수 있다.<br>\n",
    "하지만 너무 많이 늘리면 과적합에 빠지기 쉽다. 효과적인 신경망 구축을 위해서는 최적화된 신경망 층 수와 은닉층의 뉴런 수를 설계할 필요가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver(tf.global_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.get_checkpoint_state('./model')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(2):\n",
    "    sess.run(train_op, feed_dict={X:x_data, Y:y_data})\n",
    "    \n",
    "    print('Step: %d' % sess.run(global_step),\n",
    "         'Cost: %.3f' % sess.run(cost, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.save(sess, './model/dnn.ckpt',global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "print('Prediction:', sess.run(prediction, feed_dict={X:x_data}))\n",
    "print('Target:', sess.run(target, feed_dict={Y:y_data}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('Accuracy: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20171221 목\n",
    "Ch 6. Hello 딥러닝 MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([784,256], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X,W1))\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256,256], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1,W2))\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L2, W3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                              feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        \n",
    "        total_cost += cost_val\n",
    "    print('Epoch:','%04d'%(epoch+1),\n",
    "         'Avg. cost=', '{:.3f}'.format(total_cost / total_batch))\n",
    "    \n",
    "print('Optimization complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:', sess.run(accuracy,\n",
    "                          feed_dict={X: mnist.test.images,\n",
    "                                    Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20171222 금\n",
    "드롭아웃 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784,256], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X,W1))\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256,256], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1,W2))\n",
    "L2 = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L2, W3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(30):\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                              feed_dict={X: batch_xs, Y: batch_ys\n",
    "                                        ,keep_prob: 0.8})\n",
    "        \n",
    "        total_cost += cost_val\n",
    "    print('Epoch:','%04d'%(epoch+1),\n",
    "         'Avg. cost=', '{:.3f}'.format(total_cost / total_batch))\n",
    "    \n",
    "print('Optimization complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy,\n",
    "                          feed_dict={X: mnist.test.images,\n",
    "                                    Y: mnist.test.labels,\n",
    "                                    keep_prob:0.8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배치 정규화 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784,256], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X,W1))\n",
    "L1 = tf.layers.batch_normalization(L1, training=is_training)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256,256], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1,W2))\n",
    "L2 = tf.layers.batch_normalization(L2, training=is_training)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L2, W3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(30):\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                              feed_dict={X: batch_xs, Y: batch_ys\n",
    "                                        ,is_training: True})\n",
    "        \n",
    "        total_cost += cost_val\n",
    "    print('Epoch:','%04d'%(epoch+1),\n",
    "         'Avg. cost=', '{:.3f}'.format(total_cost / total_batch))\n",
    "    \n",
    "print('Optimization complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy,\n",
    "                          feed_dict={X: mnist.test.images,\n",
    "                                    Y: mnist.test.labels\n",
    "                                    ,is_training: True}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20171224 일\n",
    "matplotlib 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sess.run(model,\n",
    "                 feed_dict={X:mnist.test.images,\n",
    "                           Y:mnist.test.labels,\n",
    "                           is_training:True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    subplot = fig.add_subplot(2, 5, i + 1)\n",
    "    \n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    \n",
    "    subplot.set_title('%d'% np.argmax(labels[i]))\n",
    "    \n",
    "    subplot.imshow(mnist.test.images[i].reshape((28,28)),\n",
    "                  cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "작동 되는 걸 보니 정말 신기하다.<br>\n",
    "다음에 할 일은 위 코드에서 모르는 걸 검색해보는 것이다. 그걸 했다면 TIL에 올려도 좋다. _ am 7:04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20171225\n",
    "Chapter 7<br>\n",
    "CNN 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./mnist/data/', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                   padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                   padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.Variable(tf.random_normal([7*7*64,256],stddev=0.01))\n",
    "L3 = tf.reshape(L2, [-1, 7*7*64])\n",
    "L3 = tf.matmul(L3,W3)\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L3, W4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', '0001', 'Avg. cost:', '0.355')\n",
      "('Epoch:', '0002', 'Avg. cost:', '0.109')\n",
      "('Epoch:', '0003', 'Avg. cost:', '0.078')\n",
      "('Epoch:', '0004', 'Avg. cost:', '0.060')\n",
      "('Epoch:', '0005', 'Avg. cost:', '0.052')\n",
      "('Epoch:', '0006', 'Avg. cost:', '0.042')\n",
      "('Epoch:', '0007', 'Avg. cost:', '0.036')\n",
      "('Epoch:', '0008', 'Avg. cost:', '0.031')\n",
      "('Epoch:', '0009', 'Avg. cost:', '0.029')\n",
      "('Epoch:', '0010', 'Avg. cost:', '0.024')\n",
      "('Epoch:', '0011', 'Avg. cost:', '0.021')\n",
      "('Epoch:', '0012', 'Avg. cost:', '0.021')\n",
      "('Epoch:', '0013', 'Avg. cost:', '0.018')\n",
      "('Epoch:', '0014', 'Avg. cost:', '0.017')\n",
      "('Epoch:', '0015', 'Avg. cost:', '0.015')\n",
      "Optimization complete!\n",
      "('Acc:', 0.99010003)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                              feed_dict = {X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          keep_prob : 0.7})\n",
    "        \n",
    "        total_cost += cost_val\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "         'Avg. cost:', '{:.3f}'.format(total_cost / total_batch))\n",
    "    \n",
    "print('Optimization complete!')\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "print('Acc:', sess.run(accuracy,\n",
    "                      feed_dict={X: mnist.test.images.reshape(\n",
    "                      -1, 28, 28, 1),\n",
    "                                Y: mnist.test.labels,\n",
    "                                keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20171228 목\n",
    "ch 6 오토인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "('Epoch:', '0001', 'Avg. cost =', '0.1928')\n",
      "('Epoch:', '0002', 'Avg. cost =', '0.0562')\n",
      "('Epoch:', '0003', 'Avg. cost =', '0.0477')\n",
      "('Epoch:', '0004', 'Avg. cost =', '0.0431')\n",
      "('Epoch:', '0005', 'Avg. cost =', '0.0406')\n",
      "('Epoch:', '0006', 'Avg. cost =', '0.0381')\n",
      "('Epoch:', '0007', 'Avg. cost =', '0.0360')\n",
      "('Epoch:', '0008', 'Avg. cost =', '0.0343')\n",
      "('Epoch:', '0009', 'Avg. cost =', '0.0322')\n",
      "('Epoch:', '0010', 'Avg. cost =', '0.0314')\n",
      "('Epoch:', '0011', 'Avg. cost =', '0.0307')\n",
      "('Epoch:', '0012', 'Avg. cost =', '0.0303')\n",
      "('Epoch:', '0013', 'Avg. cost =', '0.0300')\n",
      "('Epoch:', '0014', 'Avg. cost =', '0.0292')\n",
      "('Epoch:', '0015', 'Avg. cost =', '0.0279')\n",
      "('Epoch:', '0016', 'Avg. cost =', '0.0269')\n",
      "('Epoch:', '0017', 'Avg. cost =', '0.0267')\n",
      "('Epoch:', '0018', 'Avg. cost =', '0.0265')\n",
      "('Epoch:', '0019', 'Avg. cost =', '0.0262')\n",
      "('Epoch:', '0020', 'Avg. cost =', '0.0261')\n",
      "최적화 완료!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAACNCAYAAACT6v+eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJztnXdgFNXah5/Z3fSE3kMJLTQpiiKK\nBRsoomJBRewFO3rtevXavfaOBcVeriKKXWygKEovSm+hdwiE9N2Z7493ZnY3CUjYJLub733+SZiZ\nXc7JOTPznt9bjmFZFoqiKIqiKMr+4Yl2AxRFURRFUeIZNaYURVEURVEiQI0pRVEURVGUCFBjSlEU\nRVEUJQLUmFIURVEURYkANaYURVEURVEiQI0pRVEURVGUCFBjSlEURVEUJQLUmFIURVEURYkAX03+\nZyd4hsZ1ufUfzLHGP11T2/tY2/sH2sd4QPtY+/sH2sd4QPsoqDKlKIqiKIoSAWpMKYqiKIqiRIAa\nU4qiKIqiKBFQozFTyr6R89BhAASSxc3cuNsW/ug5Luya9j9fQsa0FACaPj+lZhuoKIqiKIqLKlOK\noiiKoigRoMpUDLHj644A/N3rxXLnSsvkQiw65nXeP7g5AB//cDQAgYVLq7eBNYzRuxsAX3/xLgDd\nX7kOgFYPxp8S561Xl8UvtgNk7ADu3tybv4ZnAxBYsCRqbVMU5f8XvmZNASjp2KLcuYQl6wBYfGc7\n6i2QJLYGC4sA8EyeXUMtjD9UmVIURVEURYkAVaZihB1fd+T3Xv+r8Nwrue14+o8TAMhqswWA77t+\nyvCMDQA8fHEjANrdXruUqc2H1AHATwCA1PXxW6rEbNuSv/q/CgRVxoeazKTn6YcD0CoOlanAMQcB\ncN3ojwF4uWOHSn0+75y+1JuzVb5r8bKqbVwNk3uhxDlOffRlALqOugaA1o9Nw/L7o9auPeFr0wqA\nJh/lAvDLzK4AdH4pl8D8xfv1nd7GjQHYdlIH6n80CwCruDjSpipVxM7z+7JtkChMdxz4HQAX1vmm\n3HVjdrYG4IyMz6g/NDns3ODM3tXcyvhFjako4z9OJufPPUcBCQA8u0NcPxPPOVguWr+Z7B0zAPAk\ny+R+ZGp37mr0l3xH/dh7WFcFO3qIEbXWLw/khmP+iGZz9gtfq5YAtB0d38ZCRawamARAA+/u/fr8\nxpNLKL1AxPEGg6usWTWOL7MFD/7n9bBjC659CYCTnj8SKy8vGs3aI75mTXlgkiS0dEowATh2WzMA\nAvMrvyBzjKjhv4kB1Tf5M67960o5OXt+pM2tMryNGgKw+JnW9O8o/Vx3dClQ+4w+T88uLLo+DYDJ\nA54FoLF3Op59cEZdVne1/VvyXq9TwlE3n6IoiqIoSgTEpDK17QqRzFtfIKv5RZubUlIsqk3mh/Iz\nda2shs05C6LQwqpjd2YiAB48riI16dTuAARWlJfbl91/IAAfNHgKEGWg5Xe1zya2+vVi8uCnATj6\n1+sB6ED8BD+u/o+473qfKPPz8eaTK7wu/XBx2665R65vNE9UxpTPp1V3E/cbI0Hm7LHHzonoezJm\nJ3P2Zb8AMLGeKHiB3J2RNS4KbB7YhgGppWHHDppxDgCNd8eO+9bXMhOAuh8V0CPRC0CnH68CoONF\ns/b7exc+lAXA2eniOjro2dtoMTt2kkQ2Xyf31r03vAPAyanfu+eGNDoFAP+69TXfsGokv20GS056\n2f5Xyj595pVcSZB5f9Uhe7ymLrGlsHt6iXu6qJmocDlDDM7qMx2AUkvm+MR3+wDQ/JedWNWolNa+\nt7CiKIqiKEoNEpPK1G23fgDAmWk75ED7kJP95UeOvwCA57YcU+nvn7a5DQBpT9UFwPfTzP1qZ1VQ\n7x2JAzprxvkYO3YB4N+Qs8frLx/0IwDpnqTqblpU2d41hebeVAAyP0mIcmsqz7wrXwCg1Ars9bpJ\nPd+XX3rKj8/ypdzFG3lD8P0cvXm5N/JOl8Dz5zOlj13GS8mKjkyt1PcU17cYWX8RAJMyusjBOFKm\nPKkyPweO/K3cuaT/1ZdfrNhJmtjRT4LOx2eNco91uXszAPsbdWkd1pNlgyWx4ui/hgLQ6o1F7H3W\n1wzebHlxvH6zxAz1SpTXnRlyzYaXMwBofmUz/Bs21mj7IsXXMpOFt4ui23SKlDCo8+GfAHiKLZaU\nlgCwxl8PgFa+XC7++yIAdiyU+LGm02V+1puyBmu3eHvq5saW+lQWq18vAFZcCx8c9hoAvW2ltUJu\nFZW/8JYSRueKkvXSXCkn1PGyhZhFRVXSrpg0pp6/61wA/tNDhLP6Cy12dJHJkthDsk8eP+BTAJ5p\nPpWvC9IBODm1fCBsoSUTamqxyID9k0uhuTz0O5wjQZLZP1VLNyrFP9UZynlYXJ+X1XvSPpLMzRv6\nApDx40L5jmprXc1z3DV/MD5fHgLpk8TdGQ/9S5gkxlCCsZeb22Z2iUlOqQTvnp62HYCz0+Xldva7\no2Myc8bq14tRjz0HwHu7ZFHS+W6Zu5Udn8MG/F2VTatxig8XA/ChJmPcYwWmPG/qfPBnVNpUEU7m\n3pbTgi+Ng58U13mzNfvnjrMOE+v/7vffdo/t/lqC2NO2rdiv76xqFt4hBm2Pvbxop/aWhfuSP0o4\n492bAGj3sIQTVNVLtqrx1hMRoM/XKxnf6AsA+s24LuyapG+nc+vJFwO42ZneLh1psHg5AA3M8PdN\nLKcwmUeI8ZQjCbJ83U8WA+19KYCM7Q+F4sq8a8EQclfLe+PvIbLYu2eTvCcfbzaDnimrAHi6z0cA\n3Pmvi2n536pxSaubT1EURVEUJQJiUplK+2Sq/TN4rE6Za15o1h+Ah/plUecXkSUf71++zo2vUETd\ntHlSk6nhr+PonmgHsefEh/so94LD+P1CUaTqeiRd9Y9iL3MekmD0lF2xG6xcWbzdOgHwSJMPGbMr\nvoKSC4f04ZLmY4Gge68iN98BP0nQb+OfkkjaKefv7C/rmr+GPu9et/ZOCZytqpVTVbDjzgJa+mQd\ne9P1JwOQsKNy7khfc1Ew3mz9HaVW/K7nVp5RXvE4a+kQ+7fYCWhe85wo90v7vAXA3Zt7kfmmBOLu\nr9q7rr8o/f2STA6YIq6j1i/Ezjz1ds3mx+Oetf8lqsVj20RJnJHbmo/afxd2fXZCIq8Nl4Dtx944\nDQBz5aqaaew+4pTFKf5ElKm7Gv1Mp09Frun8WfnxLFsvLB53yFjxQS/eL+fKk/EctvIEpi9qC0Dn\nG8Q70zh/MY3tq67qfTwAm0eKgv6vl73c3XQSAJMLxYMw57oXGPKejLd/zdqI2hq/TzJFURRFUZQY\nICaVqX3Bv3ETAGnjNrnWeNon2/Z4/abLJeaoW6KPJ7eL+pH1pvj2Y9lfDLD1IMtVpBwumnQ52eNr\njyLlsO6Ehu7vM/Pa2L8VRqcx+4ijpj309GgOTixxjoZd81l+c+6eeCYAXW6ToOvArl3u+U5LpSzG\ntFNlnPskFfHt1Y8DMCD5NgCyHpkZteKCTrmSsd2f4J2dPQBI+HH/AuQXPCAxPKVWgItyZPUY2Lyl\nClpZs5x8yFz3952mzNHS+2TPM08MKVOWJfGmjko6dVsW3sLNlfoOT4YEai9+WAJ4x58qZUtMEmg9\n9K+qamqVsbVPQ7J8kiAwYs1RAKztKzG1nrQCel8lMWO3XCHV+4dnbOYo+xH75TgpWrngZFFQYyEw\n3Vu/PoselGfE4i5SEHZmMXR+QN5hoc+SeMaTJorn0gekPNDCo0fhsZ+l04slWH7459cC0On+hWTn\nSjFrs+wXAd0zZI/BH3yiXs14ojcNnxav15C0XPsqo+raXmXfpCiKoiiK8v+QuFWm9hUnk+XFu14E\nJMtq7HOyGm64Iba3Jyn5QZSZPzo/hVPav+cfEp/Q5eblcZHdVll2dQ0WP5zzomRx1CO2x8m0U66D\nqlSQS1edCEDeOSlkrxUlsaJxc7I5r3lL4qlmXPkszb0SGzDrMon9OPPTi7DmLqzStu8rniGyh14L\nXxJjPpA+taRyMTKOgvfecZJKX2yVsvppWW2nFVeurEI0KR4kRQ1fzHzNPbbWlrc9v8R+YdlvOo/n\nsklSUmZ1nsSOlIxptsfrNx5pMehQKdD6RYuX7KMSb9pvzrnUJ/ZicQJJYCJKxrxXReVoYD9HzPx8\nmj8lc/fjU2Qsh2V8BZboG5uKRYWzimJni5n153dh8emSnfZFvmQpjhl8AoEty6PZrCon1y5Y/fNQ\niRH2kMpPhVIG6NFr5N3X4XvJlK3oOWr4fHg62SUxxjcA4Il3JOO0e+JmQNRKryE6Uvep55G5uWr+\nhrXemFr0L6n6e0iSyHnzSwppsKAgmk36R3ztsgB4sIMEM9f3JDPTvq/bPChTKLBjRzSaVm0UnyQP\ntc8HyAPjga29aTBuHlCxhBvr3LVJ9lXcdbm4LQNr9+2FkzVOjJZ7hvTl0WbTq6dxlcDZd+3u7K/d\nYy0f2b9A40XXSMrywUkyh0ft6ErauPgxohw2HVI+ceWUr24EKl9rqyZo8oIY5RNHy4LsmJQixrSe\nCIDHdnOYT++5HpYHwzVMHD7ME3dmw7t8MXl/Zpy5wf1958B8ABq8Wf66/7T5wv4t6KSZPLszANk7\nYieMIu/QYKjDcyuPAyBlSe0ypADsouUUWUH3W54p83fjobLzQuEZUtG8Q8eQMS6SuT20zSyurfcu\nADNK5Pp+Sc4MTXWv/71IjmU+ZFRZ6IS6+RRFURRFUSKg1ipTxSeL0jHrrGfsIyIVXn3DDaRMiZ0V\nR0W0/1gC5w5MDNq6w+x0+uy50VcrqoO1x8pU7JEoK4yLcrrTJH9RNJtUaUILdc47yFnJV9IFYsiK\nzOcxyxX+XH8/NBtS0YeqDyNVxmNgqpSn6DP9Qpqxf67GRlnbw/79/sqDaUTs7F23ryQeGK4KLywp\noPPzoijGouvdqaT/3BHHAvDg4VmsHSDzc9kprwAwrVjm3fnfX1Xu8x3fKebrsW+EHXt8wUAAMudW\n315nkZA3rjl0k98v7ipq4a+HiKKx5cB0rMEyFw9IkHfBwtJSutl7Tn52kqjjt/e9Qr7gz3k11ew9\n8mG/0Tjaxydd3wPgsKdvpu0XElrgnbT/eyvGEvU/l/k04sLhALzX+T1OTZO5eubV4mIOWEEttNgS\n/3qSEWrKyO9BRUrwE6D/PCkI3uBauVOtFVU3f1WZUhRFURRFiYBaq0ytPknsxHRDFKlhK08AIPW7\nucTOblnh7LhI0s/vb/qUfUTaflHO8XS5TQqTxuLKtypofICkajurDt/n9aPZnEqx+Grxxf/TPnz7\nQs4ZEmP1SeNp7q7nzve2uLfm48fM7ZJC/OAW2Y/vvPYz+LW5BHjua8q4kwTye6//2Ufk3iz8sxHE\nmTJVNLgPMw552f6XjM/i0iYE4iB+xSknk/rpJrJlNy4GXXVQ2DXZlFftPT06u7FVD209AIA2N4hS\nGatlZZp9sZIld4pqc2vDBQDcPl4U1dD4r3OWS+HZwpGNOf3DSQBcUmcNAMtHyjxtHwM7A/VJSnCf\nA/XtMjmLzhlF6dlyzCkEXHe6nNvd0qKOvatPo3n57vds7SGlB5pOsp+3MTZvzbw8AJIGyM8RTc9g\n4X1ZAAzoLSU4luxsAsCqdY3wJkr/T+0k6uHjzWbs8bu7ThxBp5vF6+PfVLnSIPtCrTSmPBkZXHCk\nbD66y5T9lTY/0g6ApOLYdJP5Mltw5EiRo8tuYvzHgg5k74jNdlcFvrZteLKTBNu/tlNevA3eiO0M\nvlDuPvLL/f6sr5VUec/r3QKAVy55qdw104rlAWmU1Pyry3m4fb9OgnIn9/qADV9JBebJrx62x8/l\ndpUXVnrWTvq2yJHvKmMKGrG6qtkLhY285dyvt808g7ZE3xVUXay+1+saIN8/LDWb0tfEgIWxF/wb\nNjLiVkkKePNJqYmVnSCGBJZJh+/Fhdf5OgklMPMX8OjPpwBw2RC7EvrBYnG+3vNkzChl0Tq0/fIK\nlgx+pdxxZy4uPt7OLD1+375v2h1iHN+4wHZ7DY7NRU1g02ayrxbDJ8c+lohUpu9IsEL9959J/bNQ\nYyrHL4lmQ16QOn0dn51GwF99z1B18ymKoiiKokRArVSmlt7Xja8ayQr/tKVSdTrpm9hWdhbe1Yrx\nzcIVjmP+GgpAl9uW1Vr3HsDSK1vQ1xbjrpgl9W9a8XcUW1RzLLhf6vvMH/BiuXPjdjcC4OVbZB4k\nL4xe4kT9+0UdO/q+YXx2wFsAPHbvntXDGcWyYg7gCam/FV5tuPULf8VkWv3eKB6S6/6+sERWvi1f\nj489PivL1hGiPM7rO4ocv6Tmp2wpX0stVkkfK0r/JdwEwPazZbyKdibR5VZxbwXygy6wTneIO/C4\njmcA8EO3cQDce6+HzDNqps17otO1sxk4dgQAF74o74lUTzGDU2XngLJq6T/RJ0mUxt8OfB+Abk+M\npP2t8eMNcFj5iMzRWYc4iWaJ7rmzHhdFqsUoKeVS3UK4KlOKoiiKoigRUKuUqZ3n9wVg3jnPs9wv\nlbR3PyYxKUls2OPnYoGZpz6DE3DuUPcaWbf7a1mBzrKYrYrc3wtzk/dyZe0iYVJz/tt83B7Pv7Xu\ncACSv4yBUh7TJPiz7iC4oP9IAHI7Ju3x8oavBVe56z6VHPWZh74Vdo0TjxUPeLMl6H7GIe/hBJ5/\nu1uCsfd3j8JYp+CE3e7vZ825HIAmE+MvBd9RqNLHBo9VpPQ783HXZzKuTmmFx3qM46Xm/YHo7dNn\n+f3uPPuwcwv3+PNnScxTIEFU38NvkWfFvhb89dh6Ssuesf1+rIj1tx7OhOGyf2mKESzI+dyODgA0\ne1Oq9teU+q3KlKIoiqIoSgTUCmXKlymW+o33fARIAa9z514AQONvYztWam+UNpWsqYSSzArPB7ZI\noUCnHL6RJEqBt3Gj4DWNZQuPpTcnUhYrIKuZztcvi+qu4y8d+p77e+a3lfP9xwJeQ9Y+oXELu87r\nG3bN/Q+M4ZiUorBjCYY3pJxC+X5bx66r2oZWEU6BwIaT9u36whzZ64xDw49b/Xph/D6n6hpWjWw6\nRtKxQ8f4xYlSbiUWt5CpCl7tLdtybAgU0PDZ1H+4uvbQ+FVRdw496TwApvb+gBtuyQKg/c3RUab2\nRNon4XPvy54SQ/ToBdMpsCS+rfevVwPQ5nUvW0dK3JgorPFJ6QDZqmv8dY/T2hc+L1f7C/jidtlu\nJ6mgZt/9cW9MGT4fPb9aC8DQ9G0AvJ/XhKb3iOgWbwGuoXz9yRt7PX/47GEAbN1UB4D6jUWmntr7\ng0r9P13vvo52t9V88GHRKVKR+IjkacTzVHz0o7MAONvekBjg1ydGAeG1p0oriIDcU22qA366io7E\nn0ulQuy4c08ZITxeDCmAogbB4PmZxfKS6vKYPHditdbS/rL2TnEv90uS+fdncSreOHTv7Tem3JMN\nn5IX9dZ3C1l4rtzPp3xwIQDWzNis/N56gr3P3AWQasgCeuHRY+RQmxP4JmuCfWX4vbh6YwM6usUH\nYpucwbKgyQoxpDYExEi88MabSf06OosbdfMpiqIoiqJEQPzKAQ49O/Fgk3fDDo16ZCj15sZXmudp\nC4bz0wGfVOozUw78cI/nHIm3NGQfo0HzLgZg55xGYddm/hadtfXqU0WqSTJ8PLC1OwDpn0uQZTzV\nc2z3kbhbp52fTJ+kon+4OhynIOfojUcDsOMaKZXQeWUtKodhD2bZop3xRJMQl+sXuw4Egm722sbw\nYT8BwUrhl824mDZIAoK3YQO5qIlU6g8srOTek3GE55fZAPR/+1YWXCrKVN7DUiKiztCMmEygSJgh\n49F31jD+PCj8/fBu1g84+kmxJQlag+2inZ1HLo/5540z92af4XgAggkw/X+7DoD2n0XP5a7KlKIo\niqIoSgTErTLl7ZoNwIj/fe4e6/rGtQBkvRvbWx1URMrAlXR7RKxrq4JRyegsu5xXFA/VbfIl8rnV\nae6xdp/Yac12SjtAfZaG/YwW3joS43V7v2/cYx98K9tUtPPHl6IIEFggWzH856bLWXOKqC9LTnp1\nnz57zRuyp1arh6fYR2pfGQwzOVyR2hIojlJLKo+T1HFai7nusW0l6UAw8aO2YwY8bL5O4qhOvnwy\nAONXNAeIejHLmqDD6DW8O1QU41+7i/fgxJ6X4vkt9mL+HLWs2fX1OeWNUwG4K+trAA5LCriFgP/9\nzTkAdPiXvCtjWZXy1pd9Wm+cKnPP2W8X4LFtXQDoeIW806KpfcetMbXoGvkDn5IazEJrOcmuzmvF\nk5MoSNu7/tmQGEzv8p+Ls33BTPsltKBAsjCPX3cwHR+RgM5Yvqn/iZTPp5Ft2/ZHDRPDPuFi2Vz2\nu24fMeBvkdTNtyQzzDIga45UMI7nfv8T750oe4otLJFH3bC3pDJxa6bs8TMxQ0BGZvTCIwC48fAc\nJq2ROjaZxGYQclWz8Kg3MY+SZ2q3Xy8FoMN9Ujm8Ns9bB/+atXx8urjhL/hRMsa33lpEk9+i2aq9\n489ZDcfK7yNHXgNA3iGFdL5bXNMdVsWP4LD1VNkXdEDqRAACIa/3b+7vD0BafvQzatXNpyiKoiiK\nEgFxp0w56fQ/nfKUfeT/T/2T2oLjHlks5UJIZFWtW+HW+dBe+dkxoKfThzRW2GdXuNfVtn5XxAMr\nxd2Q/5LUS2s9Lg4UKRvL3mU+6w5RYrr89wKMORnRbFK1M+HfosIsuFNceX9M7Uzn59YD0H7jYgAC\nRZVLtIh3nED7c1YMAODLA1/nsr6i+PBnbHsGmj4v91tT4rOMx5m3/AhAwAp34nX48iqyx0VfkXJQ\nZUpRFEVRFCUC4k6ZWt9PCnaFVj59P8+uTrxLYqbiM2JKUWopx0lxyzTWRrkh+09g2UoAWg+NckNq\nAGcvyC1fyr878GdcKhrVQcHp8naZOqUFOzpJwk/9+Ak/ikt6pqwGwGuI9vNnkej5XR/fHFPzUpUp\nRVEURVGUCIg7Zaos/93WlT8GZgFgbfhr7xcriqIoyn4S2Cpblo3Obkd94q+MSzxy4/uXAbDoipcA\nuPSN6wFotSK2Yi/jzphqd4dM4EF3HBRyNLY2n1QURVEUJXLa3CtG08B7ewHQKkZLqqibT1EURVEU\nJQIMK04LXCqKoiiKosQCqkwpiqIoiqJEgBpTiqIoiqIoEaDGlKIoiqIoSgSoMaUoiqIoihIBakwp\niqIoiqJEgBpTiqIoiqIoEaDGlKIoiqIoSgSoMaUoiqIoihIBakwpiqIoiqJEgBpTiqIoiqIoEaDG\nlKIoiqIoSgSoMaUoiqIoihIBvpr8z07wDI3rXZV/MMca/3RNbe9jbe8faB/jAe1j7e8faB/jAe2j\noMqUoiiKoihKBNSoMhWvTFg/J9pNqHZqex9re/9A+1hbqO19rO39A+1jbaEyfVRlSlEURVEUJQJU\nmdoHBrboBcAPZpQbEoKvXRb+FTlV9n2x2MeqJBb7t+6Ow8l8dEqVfV8s9rGq0T7GP7W9f6B9rC1U\npo+qTCmKoiiKokRA7VWmDDv43orrJAJA/LYBS0xjryH2b8CaxaSiBACe7NEXADM/Xz7g8YJ9fbz2\n30hKonBATwAefG40ALfcfzUAjX9ajX/tuqi1bX8wfD74vikAX3b6AoAEYw4F15UAcMpF0jffz7MA\n8CQlYZaUyofNQA23dv8wfD6sgLTV8HoB8DRsQKBtM7lg6l/yM07n5B4xDLDvy3i/7zwZGZj5BfIP\nZ955vMEL4mQu7hdGmYQtZwxDj8fpuAJ4GzYAn7zyDY8zX6U/i55sQfqMFACaPVt1anmNYxhRGyNV\nphRFURRFUSKg9ipTcbyCcPhq3UwANgeKuGnNyQA82+prAOp7UuieuAsAI6ulfGDhMvlpBoKrSStO\nVpJOe+2Vr1XqZ30/OXZQYhEAyedtBMD/9rq4Ux4Dh3Xn8+xXAUgwEt3jJqJkWF67P7bCYRYV4W3c\nWD67ZUsNtrTyLHmlDwDtxgZI+GUugKtQmdu24y0uBiDgqDcE1RtfK5m7/jVry39xHI3xmn8fCsCv\nI54A4IwF5wOQMnBl1Pux9DlRrjve8OeeL+rbQ37OW4aRYKsXRoJ72rTHsKK+eOvXByCwY0cVtbgG\nsPvhKKiWabmqopEo96dhqzhmfj7eOnUACOzaVdMtjRhPzy4A5LWvw9pBcl/OGvg8APW9qYDEBjnv\nm8HP9o5CK/eTsmqi4YGyFaFqSE2tvcZUnLB6bHcAPj3kVW7MOhyA25aLO+SYv4YCUOei3RgpyQCc\nNXo4ABO6jSXdftgtuqoeAB1vqLl2VymGgeGRO8Cy7Idcgg+jjbgbVvjlsrTTNgD2qzjWX7C2ceht\n3BCAlIfWk2B4y132TYG4/gJJYmgkJcqYmsVmzBtRTf+QF8zq7+QxkvDbXCy/PVghDzkzv9D+Jfyh\n5u3QltWnNwegxRMVGFOxPsY23owMfrricQAaedMB+OmATwA4reEJBLZtj1rboLwRlXduXzL+J8fG\nrP4NgCv72UZtYWHwQsfQCATKj4VjjCQmQnMx+rGNKV/bNvhXrqrSPlSaEHePYwj5u7UFYPMhaexu\nLYZT89/lmjqzN2Bu3AyAp748Ty37b2EkJQWNyQq+PyaowMj1NZNny/XjPgXgsORckg25V5OM1LCP\nSwmA8OeT8XMm1rExGE4R2lenv/bz1vAYGElJAGw+XxYIjWftlmtmL3QXedUxdurmUxRFURRFiYC4\nUKb8x/Umab3t0tohPwNbtwG2PFsWy3TdJY6M657yl8bUiqL1UFGh/v3raWRNEwv6gRsvAyBj0kIA\nAvkF+Jo0AiA90QlAt9huSvCyp6GsmoKSdSC+AkUNT3DFYONJSWZ0n3cBGD77UgBalCyu8aZVGnvV\ntPkqcfvcfsOHAAxMXUexZbvwbDdXgVlKoiFKxuYD5VZsu6yVfM/iFTHronVWvO1T1wAw3RGhQu9F\n+x4TVcNf4fcYpsWg8yTY9e+Ppd/+VWuqocVVSKhbwXFbNm9CXU9i2GUbAqJqmDtjzy2U297DL7ZL\n5/tCea4ENogLHcsq7zqBcsccV9juU3rR/24Zw1PrSvLELUvakjKwOlpeCSwLI0HaaI7PAOBT282+\nPhDgxEnXA5D21d8A+EtL3I/6aHRCAAAgAElEQVSaGzft+XtDFBBXhY0m9rh4UkVpMgtEzfekp/PM\nVFGkshPS7ItT3I+V2s+WeSXy88/C9mQlihJ+9VIJF0k2FvIMXaq3/ftDiBrleDT8R4gKtfaaUr44\n9BUA2vgmATC7WO7TO667ipRfFgDBv1NV2gKqTCmKoiiKokRATCtTTkzGoAafcmiyrFg3BcS6vmfl\nEADua/s5XsS6LLF9vhv9dTk8WXy9K/yy8p+Y1xWA5QWN+G1xRwA6/2sFEN3ASSfIsegMk7UZTQBI\nzpkOgBliNfvt1VLeyxJMev8dfcjwSmB2h6ckhd4KWV3FFZZZLg15d/9O9En6AYD0j2UehKltMRqc\nbPgk5uncq6Xth6fIvM2zIN9ufrEdF7bLSmVAisTTHDPiKQDWXyr9ufLGG0kZP63G2l0Zll/TDoAX\n640DYPzm/gAYiQnBOViRulGGFRe04M1G7wNwbseRACREU5nahzlleL2uGu5t2ACApm9vItVWpnab\nck9eeNW/AEjyT6+u1lYaX2YLAD64/Bl22/fSqJMkLtPyryh3fVm1OOxcqagy28/NZ2RDib96aFN/\nANYubUJHVlZZu/cLj5f1Iw8GYEr20wCk2IkfRVYJSSskBtXo2l5+Ll4ZjIva2zPFVnSsGChUaSQk\nsvrDbABSfhD1rdFoOz7ONBn4owTRvneMlJZZU9qQ41MlNvGQCXKu09Xz5HrLxJMlfy9/E3neGn/M\nA2Lr+Qrga5kJwIK7M7npyAkADKvzAgB1PckkGGlh1/dOkjF7dtSLfLLTnhO3iecg4YeZVfYOiWlj\nas7YAwBYmNuNXJkz+BuL4fDRsS8D0NFXSr49s+t5pDuBxELS7QC75l45d1jSX8Evbj0RgEGfiEHm\nOW7PxtSE9XPcKqjVgSMVB7bngu26rAhPmkyQHWdJLanPFvUk4S851mapSNX76xSq1j7ui9ETcs4x\nRu59aox7rP4PS4Ey/avEDVDdYxjKyvskE+aT+s8AkGLPQz8BAh77JewaGqU4qScJyIM+O0H+/eQz\no7jvlwEABHJz5fJQF0yZ/tdUHz0ZGbx/wXMATC0S11wTO8DTKi4OD0wGrJLyBr7jkvj80ifcJIrk\nDfIde5vDNTmOeyI0GNvKlMDrV1q9DUg/Su1nUcrkRYCbt7jPVGcfF9wvxtTGQB0uf0Rc5w2XhQen\nO4s7CIZQGAk+vHZQdmCbPCs9dkLM1V0m8+zWwwBYNkzmQ8elU8tl5zrU1BgaHgPjSGmrk/ixISCu\nnQQ8/HyZJAw0GCHBynlmCSfNvUSOnbo8vO2VDDav7j467sv1Y9vz00Hi0rr8+rMA8NvtNAsK6HLX\nagAeSZH3nLU7n1FHnQ1Al4lLAAiEujdzZCHj2yz3Z2Avfa6xe9Ew3OfF8jFi+E4/Qty1dT0pFNih\nLvNKZD4GMOiYIO9Ix+223b4JkwyDWxvJAtUcMxWAc1sdTs7DMn+z/v1H2H9d2T6qm09RFEVRFCUC\nYlqZav60BDYaPh8NbAXHscrvyzoneOEWUXSMuiJPFrdrjHeiBEOuu0PKDRw/VCzSZ5vPcD+2fJ2s\nLDuyZ9dCja2E9xIw7mvejHt+l/pSByZNAmCVv4Trh/UDwLJVK+dvg2UGA/P3IRC9WvtYSQnVU1fk\n6na+nZze8ggADN/O8IsquVKsqTH0NWvqrm5SLpaxcCrWe/FQausuv9uV6y/97go6XisrpEPmyLl7\nGsu87ZkIW96V+dn4fFlaBXJ37rHfNdVH75fp3NVW6kp5O4q7z1gpQZ0SkG27QcqmkoeQc5u0NTth\nCsWWKM3m4uX/+H9Xex/3ZU6FqIOLr5C56sPrtm3YovUAmLt371cTqrOPnx03CoB3tx9Gw9f+qPAa\nT726opKD68uySv1umIEnQ/qcO0jCJhr45vPx3ScCkLp0avCL9vDcqbF52rIFzYZIAs+ovzvJz9lH\nAzDm8Ldp7M0Lu76RN40Gg0Wt8R8n6rJTMw3DU6kQiuru47YLpH2TD36as+1nJJ7wMiqepCSsAkmC\nCGyWc4bXS+qnMkZG2zZyoZ0gYXgMtxRGYHf+P7ahpsbROqwH5hQZh/lHvglAqSXtnFTo4dFzJVmL\neTJ2RmIiZp6M7ZIx4tJrPFmetxnnr+O7Lp8BUEBwPMsqUg6V7aMqU4qiKIqiKBEQm8pU2WrYISmo\nll9WsoFlIQGOToryLlkN+tZvwrJXj5mPidW54FdJnQyMnYZpB9V1ftgus1ANXagKHKXp9t+/o2+y\nU+JBfhZZAYwDuwHg2bAVAP8mu+hcSkqwTIIds7I3pSCWWHmdrCJb+JIY+LeMz4TudcMvirGgc2e+\ndv56C483E2XJUaQc5cWDhzd3SUzJW/edCkD2+NnuXlm//fsQAHpeJKuhv/q9xcRe7wDQ6+4bAWh/\ny14qWFcznh6dAfi4wzv8a5qs8FcdKUkebmyNxyw/NqEqov13OubkWe7pXwolHiKqaeaVSWYwDLzZ\nErsx7VQJbPYaaXyzTvp04jkSi+Sx5lR9O/eTZe8dCEBL3+8ADKz7F/MPOVdO2it6bxNRQXf2yaTO\nD3ZJFnuFbyT48KTLPbj0drk/Tz5OAus3ldYl4zc7kae6O1IJthydySe/fgDAK9vEO9HmbbknL/de\nyIkdpY//bvoTAM19CYxbK/dX79/lXdFuml1KoLQU+zaOKt5u8re/8faPAbh305F4ku0q7UWS+OAU\nKN11Qhfq/ml7XJxEAtPE27xZ+Jc6kfTexPLHooiTLPHy/0aRaVdp323Ju+yMC68DIOH3v7GK/wr7\nnFXqx9tVAqzrzZI+NfpaYm4XHdsKp9KDU7y0KlFlSlEURVEUJQJiU5naW5xP2dVjSOEuR6EKLczp\nlJa/+Z0P3I/0myOrsvqLl1ZRg6uIMitkx09/VHLwEid7YeS115OyeD4AgS6yTYIzmGZ+gbsVQkwU\nltsX7L7ffq5sw+HBw4TL7XgAa160WrVPOPPvvAZ/4LXTr52ieKdmiuJk9O6GJ0e2w6lnSvFRMxBw\nVZ3UKcvs62TpVHx4KekeGfhoKlIOi66TWJkEw8vk1aLMtCqV1b17vyYkYdj3oCdNVvVmYZGrju64\nUGKtXmghsTsBC5478jj7f9hY3V3YM5VROi2LgvayF10jbzAFe759r3p+n1ulTasK6tYpCPt3r6Rc\nLn3/CwDqeeTcUx1E5X518ljOeflmAOwasxx35nRuaCzXt/bJuO6wS0Cc8PStNN8ReyU8/KnQyC5X\n8fMGUSrq/iiFStvv6s78h0WhadIiuK1KkX3PtmwoMWNGCylOay7PiYlSLKsekCf8yytFGa4zPBez\nyN6qyG6fs3dgaZrHffY770BCSl2YW+VzHvucWVIaVKSi2EenrQseEGWqUUgx3EPeuwmAtj+Lt8ky\nglvHeOqJcmq2aMyiS6Uc0tAjJObavEz+NqMbfYZTuNR5LlclsWlMlcUwwjeklF/klCeknk3oZLAn\n14r7DgJgQKoE3q0sLaDhUHFPRF/MDMHjxWPvy7bxUmnz7Ltfck8H7L4d8JlU7u306wIw5Zh3nbj5\nvp4lNTcGHXMW5pJ/DuiNJZzaIcMzJEGg2CqFafPDrpH9o2owKWAfcR5a7Xx+sEscOO49b1OpHRaY\nOZ+A7ebyJNsPN8ODs11fwA4EXXiVjPnuCiant2s2gQVLqqMLe8RJlc8eYdc+W2di/V2nzEX2vool\nJW5pC7OwyD3mMlTmqeMC3WkWuoHNsYbjYje8wY2nHTb0s0uwhLhDzvj9agDaI3N0r3O1hvd1sybI\n/pDDT5WElc/WTuPs9PCkjgHrHbdkCnNHvgiEu6p9hO/l1sQ2JJvMKtxrPapo0fn8RW4Jkp358gKt\n6xhEMxZwQlMJCfEaQedMhv3iDphy7JuJsrAbmHlgMJQkirsSXNZJjIgJB8j9ZyUnB/cAbSClK2gq\nFe3rz9+FZQeSuwvqQADsyt/OmE1YNxuAE9seWmEZk5qm4KSeAGRfJga6d53hjtFn54pb/bQEqeE2\n/PjJ3NpQ/iYBO3QnAS9JZVx4wTFOdxe57rns9gSq6F2pbj5FURRFUZQIiA9lyrJcS9pRqAxfkn3K\nqtCidqoTT79ArNmBLaQwl9WvF0ZB7ASHOngbNmDryR2AcEUKZAV8yEPXAtD5E3EHmYWFbmFEs5ms\nPJ1VsCdtQ0yspCrDgntFdncK7F2QcwIQvnqONUXKwWenGad7ZrrHnt8uKyzTTjM3fL6g3O6x3dGF\nhcFxsnH6OGLJCoakyWed4OZBmdXUgX1g9djuABSYU8j6VFwEZgWBqk6CSHD+BRWYGzr8DAT7ePqC\nLTE7Tx0Xuxt4bKsa3owMXjpXKko7K97NgXyy77eTWez+7nWu7qX4anXQ5CVZvTuFf7tPupLvj5SK\n0Y7bbq1fwgLWBNJJdHeUEG5ZeB6Te0mYhMdefw+y++dNWoDlzuHou4kc5n3ZhbVXfwnAoHaicC+0\n3wmBdi04Ov1t+0pp+26ziCS7gOx7nd8DYGALO8wACyNRXpXeFi0B8K9cVd1dKEdXe1ePdksl0Wj0\n2qPY8GUWAE2nieLkmysqiyc1BdNWpJxq9WHhM7ai5c5TI6gquyUxohAiUpoq41Fwhbyv/y6ZRq9E\naU+3RJmry4a9EvIJu1hnyLPIu4dn6oT1c1z3dNEpEnKQ/GXVuahVmVIURVEURYmA+FCmIBiU7Vjb\n/2A1L3xYCgrW9Yg1+8qq3wC4ukNiDO42BOauXVxw6zdhxxxr+6AnrqP5a2JBB0LLRNhqnWdJDhBM\nJw1s3rpPxTpjiSv6TAaCq4i8c7PJMKMfeL0vLL62OSCqmjNmH78ugdVN/aIKGImJGAl2rE1uiOLm\nKDK2UrH9UlmRZfpmMihTivM5KdvR5PQOElgdwMIosuWaihSIMmVNQrcnOSRZtrcYvl6K7I7bXQfM\nxtXU4iompK9HJYtmM7CFjM/xf+cRWJYTfv0etlOp6PuqHWeLkXyJoelw4Tyu9R5rnyujQhhGUC20\n217v8FQYK4eclb23k6jogSXLg8k+9ljHQtJLmw/X8Pn5UuLg/qYSiJw3S9q1wp9KhscZQ9nr1JOR\nwY6PJOB8cs+P5Et+EhXKe1a+u39rYH30EiWOSJbnhpOYMqTTN+zuKONx+apBAGy5R4Ltd7dMJFe2\noCXrHluZTE3FsLcB2nSWlFkoaijPnTavLiKwzQ5md+ZuFGgwMQeAgB0gf8eiKzl39LcAnJMh5/4u\nEQVtzJajaJokivD0XtLmr9bNdOe0UwLphVVSEqTduJvoeL3ETqckyfOsKu/C+DGm9oTHW+6BZSQk\n8tfJL9j/kslzVRunUmxsGhmGYTAw3a4kjcjxS0rlRsl8a36YEeXiPCSLpIaUuU6qL4e+wOIBX/Nm\njGwwHoBfkIdbve8WxlTdmr3x5zlP2b+lUWzJOGV+IRuKOntlEQhg5heW/7BtRK25S4yoVg/Lg//A\nB02eyBEj6uVcu55YcnJYIHRN4LwYnYyoe5vMZOsz8rJteK5k+FFq19Jq2pj6H0ptoi2Hi4vyoOkl\nnFhXsjGzE2ReOwbz6rHdaU14nZhYZ/1FB5Bg/Bp27LW/+9EWcSU5rlynrpsnNRWzIDybrqYD0Mth\nBrD2auSFu2+7vjAfn13fbnKhLBwCiyXcAI83ZPPfKGaB2QkDbh3CjZt5/4WBAFx1j+yT2NyXbv+E\nMTuzwj5v5uWR8LpUdfe8YLtgj5N7+NGcP7nj4JPle7cFs+fcpKgaMB59bVrhobxLyjGs3s/6UQ68\nKz9CXV0D75H77e3FP5BkH6/rCXe5N/8znXVH2n/DQPgCTw7WzNg6RpTTBu+f8/l0gFQyH7dbMp1N\np0K7VczabgfYn5TMYhOTYns+zrL363u4nSRedG60zE0Cqo5ge3XzKYqiKIqiRED8SBhlAjadFaDh\n9ZZb+eWecxDpHrHi1/rtFFhHlnZWVNHGtpCd0g5bLjiQpt6JACwpFcv74v/cAkC9XdPKB6yGrhrs\nVaazb1ZF+4IZCYmV2l8qYioIsN2TG2D1+e3cwNb7V0gQ9/0HHBm83lkpxUBgayjObubJRlAW3xCQ\nv7G5WcoAuGUDTIuyZZS9jRpy5mRRNC6sI0pqwrXyXaWWh7typFK6eaUoOpa15z0kq5sGN0s//v7G\n4ueesvz9YJq40nOKJB37+oYfkmD3d+1KGbtpRW05LEnGL2DJuc/Wyr15ZnZqbJUnCaWMm86TLKvc\n0Tc9B4ib4eO14j4Z1rOB6951FCmvU/cmv7D8vRCtebyvSoN9zqn0fneTdyi2pM8vjzgLgMSu8oyx\nctZi2jXtYiK0wKk1WFJCk7cl7f+AriMBGH/aswD8kt+JL0ccY19uK6NmgIyFoopML5b+T3DLRSRT\n3CMLgIRfxdVm+Hw1qhKb23P513qpL9UpVcqJHJG2mHY+ed4kuIpTSrnPOv0IWCnlgrOdc4OXnARs\ns/+zEGWqJueqYQQTWBwsA8suG+PU0AqlpKk8G39Y5+yq4AV7ml/92jUAtO4pLlpzwfJqnaOqTCmK\noiiKokRA/ChTDvbqylEFArm55S759r9Puyup0++9FYDGG0IKQMZANVtHkTL7SDzMp/c8Qbohffqo\nQAIf671n+8jNQPiqcg84Vc8r6leNqlIQkvIfTJcuW9zPURcHnTfFLYlwbzsJ6vXWCZmapU6Kb/SL\nyoVScpj48FOM39xjSc4wdWgNgGeZBF0baWnQxE7Nni8V0LtM2MFldZ2A1vCgz8GZvVnysuzll704\n+hWmA4tE0b3z/BGsv1lWj8YUUV+azBY1ZlZudzb1tY+Nktgvb9MmDJouhUZb2jErSfZjp1wsUSzh\npFrb913eyVLqopX3Rxxl6uyWEudmJOwud88F7H1CY0OtCZZ1APm770ucj1PMMNVIoP/c4QDU/0XU\nHkK+a1+eTdWNxy5aaRXIM9DcvVuqegOd7pSYvTufFFXNzN2J15TdL8yQRAlrtcSc3vgfKUPz+2NS\nomZQ5kFsul2eVZk/71sCVFVj5uWxqp/ENK3ySNLGD77meJqIKlzQSYoDvz36GQCaepPcOLdBmVIE\n+uO1f+C11WHneetcU9p/g6u+ugL6PngVqpSK3lt+f3hyRAi+Nq24etT/gGAfJ6yfw7aAzIGsDyXm\nzdopcZxmNb8/VJlSFEVRFEWJgLhRppyy94MOHCAHnH2HfAl46siK95EZkkJZ35vKWcuPB6DBfFkh\nGvVlxezx+4M+/ijiWNu7W4uPu7k36M8eki6rps+Ss+TakhJKj5KVcfLSTe4xZ7sAt5BpqnxXXt82\nZPwpReWKu0ilx/zbdlLnpBrcYqaCFbkzhm5xUVuZurfxZErtRYl5tOxw7527ws24iGaW0N7w/STx\nXX4779CLx1Vf6r4shfXmfi99PWbwLPpkSDruoLSVQHBLjop4ZOU07u5hZ8vZK0azuDh6aqoTqzhl\nLn+Pte/Fi48CgrEMFtBkdrjCZubu5P4NklX1WitJUXbm+e6z+5L+cfTLPpTDMIJztaUopTuypV8N\nvEnuVkFLnz8UgM7/WURglxPXZytasaBIOdhjF3CeFx7DjZU5qaNkOjn7tlkBE09bUUQ//FmKVyYY\niTQ6X2IAnaKkgTxZ7RtJSW6cWDQJbJL7zVtf9k00fAl8t0oU3RPbSIFGJ+vUaNkMttrFdEMLW9q/\n1/9UlKyD61wHwJ1L3ue/CzsDUDxI9nRL+mZ6tfanIlxlPkSh+fr3z4HgOD69pT8ATzWb5pYGeDZH\nVOK1foMie8PFTglOXJT8OH3BFsb3kExNN57X6w0Wr41iuYtvl0n7B3WW583G88Sb89O/n6KOUybC\njQszGXy3xBo33GirqF5nG6/qzYaOOWMqLFA6xB13UjtJmTfS7Mlv7/1leD1uump3e2+7nWYhheeL\nYeHdZUt99jkjJdndnygWqDdrCyD1W9z9ruyfry36HoDG3iROzZR+f2TXHMo1/UwpEkMpzSMPsxXF\nUidlRL2v3D2InM07h7fqV+19qZCQmiXBarsyrusulbTWVM+v7rnEdhIs6N+1O7ZeSGUJCc582S7o\ncmP9HPf0/9pK6nHBFd8BkrJ7ZkuZwxev37zHr51fIob+3addgplvb8QdS38Hy3Ifatj3lHufGp5g\nW50U5FI/v/4oEnzgYqklVmjZQfrRK2cTJGQc3bIGpX7XiPLai7Bhw2Q8fXhdl0K9q+x9+3bnu257\nyx+bhj/gjo1lGZww7BIAtl0oL6NG82Te+bbkue49J5j5f3n13TpLLo5RHwMLHcPnK/eyt/ylroHh\nbSYGVkmWuMcSc7bg37LF/nB5F6VTMbzZ27L4yb51M6/2kKSL+2cNBiD6lbSEQSecA4DZTVyAJ9b9\n2D032K5T9/4aWcRsChjUs+trJRkytjvtumHLi5oEF63OPKnh507ouz80gcN53pT0liSysXc+AUB9\nb3pYdXOAA6cPp8X79j6i7ty090lNT4NqNKbUzacoiqIoihIBMadMhQUZh7g0XHnOlpQd11bJsb34\n6g1nLzvpzinX3UDKqvCgXSe4rqaLHv4Thh2oeti4m1kyVPrhuEEclxGEp+kCpHvgzDRbxbHdTL6U\nAvvzCe7nHDUk6oSscpyxGzFC9s4KWCbeiXb19hM3yEWW+c9VpKNJyNz89jJZOc1/LtN1ZTmk2jvR\nQ+gYBnFS6n8vljF/9FC7HMKWRVXb3irEdApSOuVJ7D29LH9pcKUfMmYZ4tVktyWfK7DP1f95RfQL\ns4a6TZ0EidD5ZgfeDq87AwCvke6u9C/oLAqy6ffHRBD2PmNZ+HbKWDT8Ww75FkmixNZTOvH7RFE3\nnFIW/31pGM2YEvYVTgIQhhH1xJBQVSpUQTMd74WdWp8w106xLwx5BziqZEKiO58dF6bjsv05vwuX\n1JU/lH/jpmrowX4SCGAukZvLY++u8OjICwFY+sT3jFktiTFOsHlLHziJLstKZfxP/VhcYh3umwtm\ndD02ofPIsgtRW/5SzAIZh5WnybM0y5fqXuc8Ux/aKm7YzOGrMcsmOtnvG7Oa3dGqTCmKoiiKokRA\nzClT/4izkrStzfteed21vC9Z3R+AlPHlU8ljTZFyCOyQQMjOz66n7zxJya1znuwOflOWxEx1TtjK\n8lLx+x9tq08+vO7WJR/mSRp++0SJxVle0oTHPj8dgLb8URPd2DN7UZXOyRD1xSSZJbOkDx0CIfFE\nVsyWdAxnqhT+W3dCBkeNlb/7xAPGAeV3MAfceLYNgULOWyAryYwzZcVr5m+p9ubuFyHKixNTEti6\nNfyaUJXHKWGSlMS2g6W/efZcmFUsadyBLduqq7X7RdnSHSAB9AAFVjDA652d3eWcvdedfDj6sUOV\nwZovpS48dp8D9tg0/nWDOz8dVXXSLU9ywu6b5XpbBNreQ/qbPWY7LFhSY+2uFM4ebWViZMPiq+x5\naiQmuEqWuw+sHXMz5oMT2XBWXefT1dfeCHCSqpK+k+KV307rwDunyn59Y/7zjHvd0KkjAGh/nXgA\n2m2Td6UZY+q/qyKF3Fcn9ZOA8tBn6k+Fcl9OOUKeKWZ++cKe7nhXcxB93BlTTrZGt5/ECOmXZLLb\nDmjdOiTZvqr8H3RvTFg/JxgcHSX8Oatp8IZI7bwpN/jzSB2j0An1TJq4FoyWzWGzvIzcWltWM/e6\nskZULPTRxTaE39slWRk/b+1MhzvkIeC80Ayvt1IZJFHtn31zB3btIuVEcRFkPyXVdz8+/XkAvFhc\nf7NUYq4zU+rZmFu3k1YgMr25Dy/jaPbRdeWVlgQ3Zy53UfmKyZ5GDUldJY+ZYz6Umm8d37ANRrP8\nbgRRHceK6tzYGaVPbpQs4jdbT2bcWmlfurEy+LlK1K6LhXtxj6654hLMMnXp63iSXYO46W8y1xvZ\nBacDFRhSsdA/wL0vjRS7KridzVfRc8VI8AWNKQfbGGv5yBTmPRJ+KhaeN5bf74ZCeNIlJMSpNRjY\ntp0Gb0qy0m1/XSGfM02yZkqm4r6YTlF93oTse2h0lsDzx5u/Y58VI7/UCvDIFZcB4Ns1c7/+n6rs\no7r5FEVRFEVRIiDulClntXBkxmL30HZHqm5rKzOb9px6XhGhlqkT0FZTFnmFNVr2srp1XQuV3GMw\nmn0si9Pnb7vVs49sLH9NBS6XvRHV/oVK5PbYdbhJVoV33dTHPZXKVGD/06qjOk/3Jcg4dN7av/vX\nrafV0+HuwMBeAkFjaZ4Cbj82ny6K8LM/ZrFho6jjHY1V9jWBYMX/Pal2IcRcH0Pwr9/A4U/fBMBN\nIz4B4J2Rp5L9g11XqaK9QcsQM/2z70vTCSjfC1ZRMYYdxG0V//NeoLHzvLFdmRX10Rmj2Qvl0kq6\nuaL6vAlpa91X5X2eZMj4OG7ox7Z1I3GzvA/N/UxWqso+qjKlKIqiKIoSAXGnTBm2b3hUx2z5CfSY\nZVvgf86L+PtjZYVYncRFHyMI6I2L/kVI3PTRsva7QnYs9dG/QdTTb7vVo6NhBwyFztH9DOCNpT4C\nYFm0fF9U7w+flnIlCcyo8Lp9Ieb6Vxa7H5EkKMWCcrq3c1VRvTyafdzRT4py56ySRIJr2hwRcrbq\nSshE2kdVphRFURRFUSIg7pQp/9p15Y7NOyg201UVRamFxFkZhMoSqGTMqaLUBOGKVOwRN8rUhPVz\nKqwgXZuo7X2s7f0D7WNtobb3sbb3D7SPtYV46WPcGFOKoiiKoiixiGHVcslaURRFURSlOlFlSlEU\nRVEUJQLUmFIURVEURYkANaYURVEURVEiQI0pRVEURVGUCFBjSlEURVEUJQLUmFIURVEURYkANaYU\nRVEURVEiQI0pRVEURVGUCFBjSlEURVEUJQLUmFIURVEURYkANaYURVEURVEiQI0pRVEURVGUCFBj\nSlEURVEUJQLUmFIURVEURYkANaYURVEURVEiQI0pRVEURVGUCFBjSlEURVEUJQLUmFIURVEURYkA\nNaYURVEURVEiQI0pRembnEkAAAAqSURBVFEURVGUCFBjSlEURVEUJQLUmFIURVEURYkANaYURVEU\nRVEi4P8A+Zg/clUmJIUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7facb007ac10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 대표적인 비지도(Unsupervised) 학습 방법인 Autoencoder 를 구현해봅니다.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "learning_rate = 0.01\n",
    "training_epoch = 20\n",
    "batch_size = 100\n",
    "# 신경망 레이어 구성 옵션\n",
    "n_hidden = 256  # 히든 레이어의 뉴런 갯수\n",
    "n_input = 28*28   # 입력값 크기 - 이미지 픽셀수\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "# Y 가 없습니다. 입력값을 Y로 사용하기 때문입니다.\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "\n",
    "# 인코더 레이어와 디코더 레이어의 가중치와 편향 변수를 설정합니다.\n",
    "# 다음과 같이 이어지는 레이어를 구성하기 위한 값들 입니다.\n",
    "# input -> encode -> decode -> output\n",
    "W_encode = tf.Variable(tf.random_normal([n_input, n_hidden]))\n",
    "b_encode = tf.Variable(tf.random_normal([n_hidden]))\n",
    "# sigmoid 함수를 이용해 신경망 레이어를 구성합니다.\n",
    "# sigmoid(X * W + b)\n",
    "# 인코더 레이어 구성\n",
    "encoder = tf.nn.sigmoid(\n",
    "                tf.add(tf.matmul(X, W_encode), b_encode))\n",
    "\n",
    "# encode 의 아웃풋 크기를 입력값보다 작은 크기로 만들어 정보를 압축하여 특성을 뽑아내고,\n",
    "# decode 의 출력을 입력값과 동일한 크기를 갖도록하여 입력과 똑같은 아웃풋을 만들어 내도록 합니다.\n",
    "# 히든 레이어의 구성과 특성치을 뽑아내는 알고리즘을 변경하여 다양한 오토인코더를 만들 수 있습니다.\n",
    "W_decode = tf.Variable(tf.random_normal([n_hidden, n_input]))\n",
    "b_decode = tf.Variable(tf.random_normal([n_input]))\n",
    "# 디코더 레이어 구성\n",
    "# 이 디코더가 최종 모델이 됩니다.\n",
    "decoder = tf.nn.sigmoid(\n",
    "                tf.add(tf.matmul(encoder, W_decode), b_decode))\n",
    "\n",
    "# 디코더는 인풋과 최대한 같은 결과를 내야 하므로, 디코딩한 결과를 평가하기 위해\n",
    "# 입력 값인 X 값을 평가를 위한 실측 결과 값으로하여 decoder 와의 차이를 손실값으로 설정합니다.\n",
    "cost = tf.reduce_mean(tf.pow(X - decoder, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "for epoch in range(training_epoch):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'Avg. cost =', '{:.4f}'.format(total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "# 입력값(위쪽)과 모델이 생성한 값(아래쪽)을 시각적으로 비교해봅니다.\n",
    "######\n",
    "sample_size = 10\n",
    "\n",
    "samples = sess.run(decoder,\n",
    "                   feed_dict={X: mnist.test.images[:sample_size]})\n",
    "\n",
    "fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "\n",
    "for i in range(sample_size):\n",
    "    ax[0][i].set_axis_off()\n",
    "    ax[1][i].set_axis_off()\n",
    "    ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "    ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20180101 월\n",
    "\n",
    "Ch 6 순환 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "('Epoch:', '0001', 'Avg. cost =', '0.494')\n",
      "('Epoch:', '0002', 'Avg. cost =', '0.240')\n",
      "('Epoch:', '0003', 'Avg. cost =', '0.190')\n",
      "('Epoch:', '0004', 'Avg. cost =', '0.157')\n",
      "('Epoch:', '0005', 'Avg. cost =', '0.142')\n",
      "('Epoch:', '0006', 'Avg. cost =', '0.133')\n",
      "('Epoch:', '0007', 'Avg. cost =', '0.117')\n",
      "('Epoch:', '0008', 'Avg. cost =', '0.112')\n",
      "('Epoch:', '0009', 'Avg. cost =', '0.110')\n",
      "('Epoch:', '0010', 'Avg. cost =', '0.109')\n",
      "('Epoch:', '0011', 'Avg. cost =', '0.093')\n",
      "('Epoch:', '0012', 'Avg. cost =', '0.091')\n",
      "('Epoch:', '0013', 'Avg. cost =', '0.095')\n",
      "('Epoch:', '0014', 'Avg. cost =', '0.086')\n",
      "('Epoch:', '0015', 'Avg. cost =', '0.090')\n",
      "('Epoch:', '0016', 'Avg. cost =', '0.083')\n",
      "('Epoch:', '0017', 'Avg. cost =', '0.085')\n",
      "('Epoch:', '0018', 'Avg. cost =', '0.080')\n",
      "('Epoch:', '0019', 'Avg. cost =', '0.078')\n",
      "('Epoch:', '0020', 'Avg. cost =', '0.078')\n",
      "('Epoch:', '0021', 'Avg. cost =', '0.075')\n",
      "('Epoch:', '0022', 'Avg. cost =', '0.077')\n",
      "('Epoch:', '0023', 'Avg. cost =', '0.068')\n",
      "('Epoch:', '0024', 'Avg. cost =', '0.072')\n",
      "('Epoch:', '0025', 'Avg. cost =', '0.071')\n",
      "('Epoch:', '0026', 'Avg. cost =', '0.066')\n",
      "('Epoch:', '0027', 'Avg. cost =', '0.067')\n",
      "('Epoch:', '0028', 'Avg. cost =', '0.069')\n",
      "('Epoch:', '0029', 'Avg. cost =', '0.066')\n",
      "('Epoch:', '0030', 'Avg. cost =', '0.063')\n",
      "최적화 완료!\n",
      "('\\xec\\xa0\\x95\\xed\\x99\\x95\\xeb\\x8f\\x84:', 0.96960002)\n"
     ]
    }
   ],
   "source": [
    "# 머신러닝 학습의 Hello World 와 같은 MNIST(손글씨 숫자 인식) 문제를 신경망으로 풀어봅니다.\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "learning_rate = 0.001\n",
    "total_epoch = 30\n",
    "batch_size = 128\n",
    "\n",
    "# RNN 은 순서가 있는 자료를 다루므로,\n",
    "# 한 번에 입력받는 갯수와, 총 몇 단계로 이루어져있는 데이터를 받을지를 설정해야합니다.\n",
    "# 이를 위해 가로 픽셀수를 n_input 으로, 세로 픽셀수를 입력 단계인 n_step 으로 설정하였습니다.\n",
    "n_input = 28\n",
    "n_step = 28\n",
    "n_hidden = 128\n",
    "n_class = 10\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "X = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
    "Y = tf.placeholder(tf.float32, [None, n_class])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
    "b = tf.Variable(tf.random_normal([n_class]))\n",
    "\n",
    "# RNN 에 학습에 사용할 셀을 생성합니다\n",
    "# 다음 함수들을 사용하면 다른 구조의 셀로 간단하게 변경할 수 있습니다\n",
    "# BasicRNNCell,BasicLSTMCell,GRUCell\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "\n",
    "# RNN 신경망을 생성합니다\n",
    "# 원래는 다음과 같은 과정을 거쳐야 하지만\n",
    "# states = tf.zeros(batch_size)\n",
    "# for i in range(n_step):\n",
    "#     outputs, states = cell(X[[:, i]], states)\n",
    "# ...\n",
    "# 다음처럼 tf.nn.dynamic_rnn 함수를 사용하면\n",
    "# CNN 의 tf.nn.conv2d 함수처럼 간단하게 RNN 신경망을 만들어줍니다.\n",
    "# 겁나 매직!!\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "# 결과를 Y의 다음 형식과 바꿔야 하기 때문에\n",
    "# Y : [batch_size, n_class]\n",
    "# outputs 의 형태를 이에 맞춰 변경해야합니다.\n",
    "# outputs : [batch_size, n_step, n_hidden]\n",
    "#        -> [n_step, batch_size, n_hidden]\n",
    "#        -> [batch_size, n_hidden]\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "outputs = outputs[-1]\n",
    "model = tf.matmul(outputs, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # X 데이터를 RNN 입력 데이터에 맞게 [batch_size, n_step, n_input] 형태로 변환합니다.\n",
    "        batch_xs = batch_xs.reshape((batch_size, n_step, n_input))\n",
    "\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "######\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "test_batch_size = len(mnist.test.images)\n",
    "test_xs = mnist.test.images.reshape(test_batch_size, n_step, n_input)\n",
    "test_ys = mnist.test.labels\n",
    "\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                       feed_dict={X: test_xs, Y: test_ys}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
