{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch 5. 텐서보드와 모델 재사용\n",
    "\n",
    "목표 : <br>\n",
    "오늘의 공부 목표는 Ch 5의 텐서보드 사용 및 모델 재사용 코드를 숙달하는 것입니다. 숙달의 의미는 안 보고도 짤 수 있는 걸 의미합니다. 우선 P.74부터 존재하는 코드를 작성한 후 스스로 주석을 다는 작업을 하겠습니다.(a.m. 9:27 시작)\n",
    "<br>\n",
    "참조 : [골빈 해커의 3분 딥러닝](https://github.com/golbin/TensorFlow-Tutorials) 소스 코드를 학습용으로 사용. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import modules\n",
    "# 신경망 구축 및 텐서보드 사용+csv파일 로드 및 전치 사용을 위해\n",
    "# Tensorflow와 Numpy를 import함.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 2. Load .csv data\n",
    "# './filename.format'에서 ./는 현재 폴더 혹은 디렉토리를 가리킨다.\n",
    "# delimiter는 기본값은 공백(white space)이고, string을 개별 값들로 분리하는 기준.\n",
    "# unpack은 반환할 array를 transpose할지 말지 정하는 것이다. True일 경우 transpose되어 반환된다.\n",
    "data = np.loadtxt('./data.csv', delimiter=',',\n",
    "                 unpack=True, dtype='float32')\n",
    "\n",
    "# unpack에 의해 transpose되었으므로 데이터를 x와 y로 분류할 때 한 번 더\n",
    "# transpose를 취해준다.\n",
    "x_data = np.transpose(data[0:2])\n",
    "y_data = np.transpose(data[2:])\n",
    "\n",
    "# 3. 모델을 저장할 때 쓸 변수 선언\n",
    "# 학습 횟수를 카운트하는 변수임\n",
    "# trainable은 이 변수가 학습에 직접 사용될 것인지 아닌지를 정해 줌. Default는 True.\n",
    "# 학습에 직접 사용될 경우 해당 변수는 Optimizer class가 사용함.\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "# 4. Model\n",
    "# 입력 레이어\n",
    "# x_data와 y_data를 담을 그릇\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# 첫 번재 레이어\n",
    "# tf.random uniform(shape, minval,maxval,dtype,seed,name)\n",
    "# -1., 1.일 경우 최소 -1에서 최대 1 사이의 수가 생성된다.\n",
    "W1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.))\n",
    "L1 = tf.nn.relu(tf.matmul(X,W1))\n",
    "\n",
    "# 두 번째 레이어\n",
    "W2 = tf.Variable(tf.random_uniform([10, 20], -1., 1.))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "\n",
    "# 출력 레이어\n",
    "W3 = tf.Variable(tf.random_uniform([20, 3], -1., 1.))\n",
    "model = tf.matmul(L2, W3)\n",
    "\n",
    "# Cost for training\n",
    "# tf.nn.softmax_cross_entropy_with_logits : logits와 labels 사이의 소프트맥스 크로스 엔트로피를 계산해준다.(소프트맥스 크로스 엔트로피 공부할 것 [  ])\n",
    "# 보통 labels는 원핫인코딩과 같은 형태를 입력하며, 스칼라값 혹은 1 class값만을 넣을 때는 sparse_softmax_cross_entropy_with_logits를 사용하라.\n",
    "# labels와 logits는 shape과 datatype이 같아야 한다. 예를 들어 [batch_size, num_classes] 같이.\n",
    "# tf.reduce_mean(tensor, axis)은 원소들의 평균을 구해 반환함으로써 Tensor의 차원을 축소해준다.\n",
    "# axis = 0일 때, 그냥 모든 원소의 평균을 구해서 반환한다.\n",
    "# axis = 1일 때, column끼리 평균을 내서 반환한다(2차 행렬에서의 그 column).\n",
    "# axis = 2일 때, row끼리 평균을 내서 반환한다(2차 행렬에서의 그 row).\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=model))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate =0.01) # Question : learning rate를 decay하려면 어떻게 해야 할까? [  ]\n",
    "train_op = optimizer.minimize(cost, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a.m. 10:31) 일단 모델 코드까지만 주석을 달아봤다.\n",
    "현재 더 찾아보고 싶은 부분은<br>\n",
    "1. 소프트맥스 크로스 엔트로피\n",
    "2. tf.train 클래스\n",
    "3. tf.train Optimizer에서 learning rate를 decay하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018년 1월 21일 일요일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "# 모델을 저장하고 불러오는 API인 tf.train.Saver를 초기화합니다.\n",
    "# global_variables 함수를 통해 앞서 정의하였던 변수들을 저장하거나 불러올 변수들로 설정합니다.\n",
    "# tf.Variable이나 tf.get_variable을 쓰면 생성되는 변수들은 자동적으로 graphkeys에 저장이 되는데,\n",
    "# tf.global_variables는 그렇게 저장된 변수들의 리스트를 반환한다.\n",
    "# 참고로 global variable이란 분산 환경에서 모든 machine에 사용할 수 있는 변수를 지칭한다.\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "# get_checkpoint_state는 디렉토리에 있는 모델 파일의 CheckPointState의 proto를 반환한다. 없으면 아무것도 반환하지 않는다.\n",
    "ckpt = tf.train.get_checkpoint_state('./model')\n",
    "# ckpt의 모델 폴더에 체크포인트가 존재하면\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    # 세션에 체크포인트 상태를 복원한다.\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    # 존재하지 않으면 전역 변수를 초기화한다.\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018년 1월 22일 월요일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Step: 3, ', 'Cost: 1.168')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument None has invalid type <type 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-dcd5410aca33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# 적절한 시점에 저장할 값들을 수집하고 저장합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cho/Projects/keras_talk/venv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cho/Projects/keras_talk/venv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1109\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cho/Projects/keras_talk/venv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \"\"\"\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cho/Projects/keras_talk/venv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m       raise TypeError('Fetch argument %r has invalid type %r' %\n\u001b[0;32m--> 230\u001b[0;31m                       (fetch, type(fetch)))\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument None has invalid type <type 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# 최적화 진행\n",
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    print('Step: %d, ' % sess.run(global_step),\n",
    "          'Cost: %.3f' % sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "    # 적절한 시점에 저장할 값들을 수집하고 저장합니다.\n",
    "    summary = sess.run(merged, feed_dict={X: x_data, Y: y_data})\n",
    "    writer.add_summary(summary, global_step=sess.run(global_step))\n",
    "\n",
    "saver.save(sess, './model/dnn.ckpt', global_step=global_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
